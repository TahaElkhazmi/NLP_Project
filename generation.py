import json
import csv
import os
from langchain_openai import ChatOpenAI
from tqdm import tqdm  # Ù„Ø¥Ø¶Ø§ÙØ© Progress Bar

# ØªØ­Ø¯ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª JSON Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙ‚Ù‡ÙŠØ©
data_files = ["data1.json", "data2.json", "data3.json", "data4.json"]

# Ø§Ø³Ù… Ù…Ù„Ù CSV Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡
evaluation_csv = "evaluation_dataset.csv"

# Ø¶Ø¨Ø· Ù…ÙØªØ§Ø­ OpenAI ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…Ø¶Ø¨ÙˆØ·Ù‹Ø§
if os.getenv("OPENAI_API_KEY") is None:
    with open("key.txt", "r") as f:
        os.environ["OPENAI_API_KEY"] = f.readline().strip()
    print("âœ… ØªÙ… Ø¶Ø¨Ø· Ù…ÙØªØ§Ø­ OpenAI ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù…Ù† key.txt")


def load_json_data(file_path):
    """ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù JSON """
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def generate_smart_question(title, content):
    """ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o-mini Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ø°ÙƒÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ """
    prompt = f"""
    Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© ÙÙ‚Ù‡ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±.
    Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {title}
    Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content[:500]}...

    Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¤Ø§Ù„ ÙÙ‚Ù‡ÙŠ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©.
    """

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)
    response = llm.invoke([prompt])
    return response.content.strip()


def extract_questions_and_answers():
    """ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù…Ù† Ù…Ù„ÙØ§Øª JSON """
    dataset = []
    total_questions = 0
    all_entries = []

    for file in data_files:
        if not os.path.exists(file):
            print(f"ØªØ­Ø°ÙŠØ±: Ø§Ù„Ù…Ù„Ù {file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠÙ‡.")
            continue

        data = load_json_data(file)
        for category, entries in data.items():
            all_entries.extend(entries)

    print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {len(all_entries)}")

    for entry in tqdm(all_entries, desc="ğŸ”„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", unit=" Ø³Ø¤Ø§Ù„"):
        question = generate_smart_question(entry['lecture_title'], entry['content'])
        answer = entry['content'][:500] + "..."  # Ø§Ù‚ØªØ¨Ø§Ø³ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙƒØ¥Ø¬Ø§Ø¨Ø©
        dataset.append((question, answer))
        total_questions += 1

    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {total_questions} Ø³Ø¤Ø§Ù„Ù‹Ø§ ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ….")
    return dataset


def save_to_csv(dataset, file_path):
    """ Ø­ÙØ¸ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙŠ Ù…Ù„Ù CSV """
    with open(file_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(["ID", "Question", "Expected Answer"])
        for idx, (question, answer) in enumerate(dataset, start=1):
            writer.writerow([idx, question, answer])


def main():
    print("ğŸ“Œ ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o-mini...")
    dataset = extract_questions_and_answers()
    save_to_csv(dataset, evaluation_csv)
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {evaluation_csv} Ø¨Ù†Ø¬Ø§Ø­!")


if __name__ == "__main__":
    main()
