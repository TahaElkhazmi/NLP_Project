import os
import logging
import json
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma

# ุฅุนุฏุงุฏ ุชุณุฌูู ุงููุนูููุงุช
logging.basicConfig(level=logging.INFO)

# ุชุญููู ููุชุงุญ OpenAI API
def configure_openai_api_key():
    if os.getenv("OPENAI_API_KEY") is None:
        with open('key.txt', 'r') as f:
            os.environ["OPENAI_API_KEY"] = f.readline().strip()
    assert os.getenv("OPENAI_API_KEY", "").startswith("sk-"), "Invalid OpenAI API key"
    logging.info("โ OpenAI API key configured")

configure_openai_api_key()

# ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุชุฌููุฉ
def load_vector_store(vector_store_path="./vector_store"):
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
    return Chroma(persist_directory=vector_store_path, embedding_function=embeddings)

# ุงุณุชุฑุฌุงุน ุงููุณุชูุฏุงุช ุฐุงุช ุงูุตูุฉ
def retrieve_documents(query, top_k=10):
    db = load_vector_store()
    retriever = db.as_retriever(search_kwargs={"k": top_k})
    docs = retriever.invoke(query)

    if not docs:
        logging.warning("โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู ุฃู ูุณุชูุฏุงุช ุฐุงุช ุตูุฉ.")
        return []

    return docs

# ุงูุชุฃูุฏ ูู ุฃู ุงูุณุคุงู ูููู
def is_fiqh_related(query, relevant_docs):
    keywords = ["ุญูู", "ุดุฑูุท", "ุงูุตูุงุฉ", "ุงูุฒูุงุฉ", "ุงูุญุฌ", "ุงูุตูู", "ุงูุทูุงุฑุฉ", "ุงููุถูุก", "ุงูููุงุฑุฉ", "ุงูุทูุงู",
                "ุงูููุฑุงุซ", "ูุฌูุฒ", "ูุง ูุฌูุฒ", "ุงููุตุฑ", "ุงูุฑูุนุฉ", "ุงูุชููู", "ุงูุทูุงู", "ุงูุฅุญุฑุงู", "ุงูููุฉ", "ุงููุฏูุฉ",
                "ุงูุณุนู", "ูุง ุญูู", "ููู", "ูู ูุฌูุฒ", "ูุง ูู", "ูุง ูู", "ูุชู", "ูู ูุฌุจ"]
    return any(word in query for word in keywords) or bool(relevant_docs)

# ุชูููุฏ ุงูุฅุฌุงุจุฉ ุจูุงุกู ุนูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ููุท
def generate_response(query):
    logging.info(f"๐ Querying: {query}")
    relevant_docs = retrieve_documents(query)

    if not is_fiqh_related(query, relevant_docs):
        logging.warning("๐ซ ุงูุณุคุงู ุบูุฑ ูููู.")
        return "โ ููุฑุฌู ุทุฑุญ ุณุคุงู ูููู ููุท."

    if not relevant_docs:
        return "โ ูู ุฃุฌุฏ ุฅุฌุงุจุฉ ูุจุงุดุฑุฉ ููุฐุง ุงูุณุคุงูุ ููุฑุฌู ุงูุจุญุซ ูู ุงููุตุงุฏุฑ ุงูููุซููุฉ."

    # **ุชูุธูู ุงููุณุชูุฏุงุช ุฏุงุฎู Full Prompt**
    context_sections = []
    for idx, doc in enumerate(relevant_docs, 1):
        context_sections.append(f"๐ **ุงููุตุฏุฑ {idx}:**\n{doc.page_content[:1000]}...\n")

    context = "\n\n".join(context_sections)

    # **ุชุญุณูู `full_prompt` ูููุน ุงูุชูููุฏ ูุน ุงูุณูุงุญ ุจุฅุนุงุฏุฉ ุงูุตูุงุบุฉ ุนูุฏ ุชููุฑ ุงููุนูููุงุช**
    full_prompt = f"""
๐ **ุงููุนูููุงุช ุงููุณุชุฑุฌุนุฉ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช:**
{context}

๐ **ุชุนูููุงุช ูููููุฐุฌ:**
- **ูุฌุจ ุฃู ุชุณุชุฎูุต ุงูุฅุฌุงุจุฉ ููุท ููุง ูู ููุฌูุฏ ูู ุงููุนูููุงุช ุงููุณุชุฑุฌุนุฉ ุฃุนูุงู**.
- **ููููู ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงููุนูููุงุช ูููู ูุง ุชุถู ุฃู ุชูุงุตูู ุบูุฑ ููุฌูุฏุฉ ูู ุงููุณุชูุฏุงุช**.
- **ุฅุฐุง ูู ุชูู ููุงู ูุนูููุงุช ูุงููุฉุ ููุท ุฃุฐูุฑ "ุงููุนูููุงุช ุบูุฑ ูุชููุฑุฉ"**.
- **ูุง ุชูุณุฑ ุฃู ุชุถูู ุฃู ุฑุฃู ุดุฎุตูุ ุจู ุงุณุชุฎุฏู ุงููุนูููุงุช ุงููุชุงุญุฉ ููุท**.

๐น **ุงูุณุคุงู:** {query}
"""

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.0)  # ุชูููู ุงูุฅุจุฏุงุน ุฅูู 0
    refined_response = llm.invoke([full_prompt])

    response_text = refined_response.content.strip()

    # โ **ููุน ุชูููุฏ ุฅุฌุงุจุฉ ุฅุฐุง ูู ุชูู ููุงู ูุนูููุงุช ูุงููุฉ**
    if "ุงููุนูููุงุช ุบูุฑ ูุชููุฑุฉ" in response_text or response_text == "":
        return "โ ูู ุฃุฌุฏ ุฅุฌุงุจุฉ ูุจุงุดุฑุฉ ููุฐุง ุงูุณุคุงูุ ููุฑุฌู ุงูุจุญุซ ูู ุงููุตุงุฏุฑ ุงูุฑุณููุฉ."

    formatted_response = f"""
๐ **ุงูุณุคุงู:** {query}

๐ **ุงูุฅุฌุงุจุฉ:**
{response_text}

๐ **ุงููุตุฏุฑ ุงูุฃูู:** [ุงุถุบุท ููุง]({relevant_docs[0].metadata.get('url', '#')})

โ **ุฅุฐุง ุงุญุชุฌุช ุฅูู ูุฒูุฏ ูู ุงูุชูุงุตููุ ููุฑุฌู ูุฑุงุฌุนุฉ ุงููุตุงุฏุฑ ุงูููุซููุฉ ูุซู ุฏุงุฑ ุงูุฅูุชุงุก ูุงูููุฆุฉ ุงูุนุงูุฉ ููุฃููุงู.**
    """

    return formatted_response

if __name__ == "__main__":
    print("""
๐จ **ุชูุจูู ููู:**
๐ค ูุฐุง ุงูุดุงุช ุจูุช ูู ุฃุฏุงุฉ ุฏุฑุงุณูุฉ ุชุฌุฑูุจูุฉ ููุง ููุนุชุจุฑ ูุตุฏุฑูุง ุฑุณูููุง ูููุชุงูู ุฃู ุงูุฃุญูุงู ุงูุดุฑุนูุฉ.
๐ ููุฑุฌู ูุฑุงุฌุนุฉ ุงููุตุงุฏุฑ ุงูููุซููุฉ ูุซู **ุฏุงุฑ ุงูุฅูุชุงุก ูุงูููุฆุฉ ุงูุนุงูุฉ ููุฃููุงู** ููุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช ุงูููููุฉ.
    """)

    while True:
        user_input = input("๐ข ุงุทุฑุญ ุณุคุงูู ุงููููู: ")
        if user_input.lower() in ["exit", "ุฎุฑูุฌ"]:
            print("๐ด ุชู ุฅููุงุก ุงููุญุงุฏุซุฉ.")
            break
        answer = generate_response(user_input)
        print(f"๐ค ุงูุฌูุงุจ: {answer}\n")
